{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387218, 29)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = pd.read_csv(\"../Data/Filtered_311_Dataset.csv\")\n",
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Columns that are redundant (not focus of the project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387218, 18)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_col_data = filtered_data.drop(columns=['create_date_utc', 'last_action_utc', 'closed_date_utc', 'cross_street', 'street', 'street_id', 'cross_street_id', 'latitude', 'longitude', 'geo_accuracy', 'request_type_id'])\n",
    "drop_col_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365567, 18)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data = drop_col_data.dropna(subset=['neighborhood'])\n",
    "cleaned_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 365567 entries, 91 to 387217\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   _id                365567 non-null  int64  \n",
      " 1   group_id           365567 non-null  int64  \n",
      " 2   num_requests       365567 non-null  int64  \n",
      " 3   parent_closed      365567 non-null  object \n",
      " 4   status_name        365567 non-null  object \n",
      " 5   status_code        365567 non-null  int64  \n",
      " 6   dept               363091 non-null  object \n",
      " 7   request_type_name  365567 non-null  object \n",
      " 8   create_date_et     365567 non-null  object \n",
      " 9   last_action_et     365567 non-null  object \n",
      " 10  closed_date_et     312003 non-null  object \n",
      " 11  origin             365567 non-null  object \n",
      " 12  city               365567 non-null  object \n",
      " 13  neighborhood       365567 non-null  object \n",
      " 14  census_tract       233900 non-null  float64\n",
      " 15  council_district   365492 non-null  float64\n",
      " 16  ward               365541 non-null  float64\n",
      " 17  police_zone        365517 non-null  float64\n",
      "dtypes: float64(4), int64(4), object(10)\n",
      "memory usage: 53.0+ MB\n"
     ]
    }
   ],
   "source": [
    "cleaned_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                       0\n",
       "group_id                  0\n",
       "num_requests              0\n",
       "parent_closed             0\n",
       "status_name               0\n",
       "status_code               0\n",
       "dept                   2476\n",
       "request_type_name         0\n",
       "create_date_et            0\n",
       "last_action_et            0\n",
       "closed_date_et        53564\n",
       "origin                    0\n",
       "city                      0\n",
       "neighborhood              0\n",
       "census_tract         131667\n",
       "council_district         75\n",
       "ward                     26\n",
       "police_zone              50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h6/93p_2snd3bl3v008snqlzq7m0000gn/T/ipykernel_98985/707828681.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_data['create_date_et'] = pd.to_datetime(cleaned_data['create_date_et'], errors='coerce')\n",
      "/var/folders/h6/93p_2snd3bl3v008snqlzq7m0000gn/T/ipykernel_98985/707828681.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_data['last_action_et'] = pd.to_datetime(cleaned_data['last_action_et'], errors='coerce')\n",
      "/var/folders/h6/93p_2snd3bl3v008snqlzq7m0000gn/T/ipykernel_98985/707828681.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_data['closed_date_et'] = pd.to_datetime(cleaned_data['closed_date_et'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to DateTime format\n",
    "cleaned_data['create_date_et'] = pd.to_datetime(cleaned_data['create_date_et'], errors='coerce')\n",
    "cleaned_data['last_action_et'] = pd.to_datetime(cleaned_data['last_action_et'], errors='coerce')\n",
    "cleaned_data['closed_date_et'] = pd.to_datetime(cleaned_data['closed_date_et'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Windgap' 'Overbrook' 'Mount Oliver Borough' 'Mt. Oliver'\n",
      " 'Swisshelm Park' 'Westwood' 'Banksville' 'Fairywood' 'Knoxville'\n",
      " 'Ridgemont' 'East Carnegie' 'Oakwood']\n",
      "Missing values in police_zone: 0\n"
     ]
    }
   ],
   "source": [
    "# Fill in missing value for column police_zone\n",
    "# Fill values based on https://pghsafeneighborhoods.wordpress.com/wp-content/uploads/2008/06/zones-by-neighborhood.pdf\n",
    "\n",
    "# Neighborhoods without police zone\n",
    "unique_neighborhoods = cleaned_data.loc[cleaned_data['police_zone'].isna(), 'neighborhood'].unique()\n",
    "print(unique_neighborhoods)\n",
    "\n",
    "# Fill in missing values for police_zone\n",
    "dict_neighborhoods_policezone = {'Windgap': 6.0, \n",
    "                                 'Overbrook': 3.0,\n",
    "                                 'Mount Oliver Borough': 3.9,\n",
    "                                 'Mt. Oliver': 3.0,\n",
    "                                 'Swisshelm Park': 4.0,\n",
    "                                 'Westwood': 6.0,\n",
    "                                 'Banksville': 3.0,\n",
    "                                 'Fairywood': 6.0,\n",
    "                                 'Knoxville': 3.0,\n",
    "                                 'Ridgemont': 3.0,\n",
    "                                 'East Carnegie': 6.0,\n",
    "                                 'Oakwood': 6.0\n",
    "}\n",
    "\n",
    "for neighborhood, police_zone in dict_neighborhoods_policezone.items():\n",
    "    cleaned_data.loc[cleaned_data['neighborhood'] == neighborhood, 'police_zone'] = police_zone\n",
    "\n",
    "# Check if there are still missing values\n",
    "missing_values_count = cleaned_data['police_zone'].isna().sum()\n",
    "print(f\"Missing values in police_zone: {missing_values_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                       0\n",
       "group_id                  0\n",
       "num_requests              0\n",
       "parent_closed             0\n",
       "status_name               0\n",
       "status_code               0\n",
       "dept                   2476\n",
       "request_type_name         0\n",
       "create_date_et            0\n",
       "last_action_et            0\n",
       "closed_date_et        53564\n",
       "origin                    0\n",
       "city                      0\n",
       "neighborhood              0\n",
       "census_tract         131667\n",
       "council_district         75\n",
       "ward                     26\n",
       "police_zone               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_encoded = pd.get_dummies(cleaned_data, drop_first=True, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365567, 486)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Sparse Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import arange\n",
    "# import altair as alt\n",
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# data = cleaned_data_encoded.values\n",
    "# X = data[:, :-1]\n",
    "# y = data[:, -1]\n",
    "\n",
    "# print(X.shape, y.shape)\n",
    "\n",
    "# thresholds = arange(0.0, 0.55, 0.05)\n",
    "\n",
    "# results = []\n",
    "# for t in thresholds:\n",
    "    \n",
    "#     vt = VarianceThreshold(threshold=t)\n",
    "    \n",
    "#     X_sel = vt.fit_transform(X)\n",
    "#     rows, cols = X_sel.shape\n",
    "#     n_features = cols\n",
    "#     print('Threshold=%.2f, Features=%d' % (t, n_features))\n",
    "    \n",
    "#     results.append(n_features)\n",
    "    \n",
    "# d2 = pd.DataFrame({'threshold': thresholds, 'n_features': results})\n",
    "# alt.Chart(d2).mark_line().encode(\n",
    "#     x='threshold',\n",
    "#     y='n_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_encoded.to_csv(\"../Data/CleanedData_311_Dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
